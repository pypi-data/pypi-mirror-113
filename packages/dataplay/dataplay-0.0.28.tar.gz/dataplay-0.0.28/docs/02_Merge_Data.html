# default_exp merge<p>This Coding Notebook is the <strong>second</strong> in a series.</p>
<p>An Interactive version can be found here <a href="https://colab.research.google.com/github/karpatic/dataplay/blob/master/notebooks/02_Merge_Data.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>.</p>
<p>This colab and more can be found on our <a href="https://karpatic.github.io/dataplay/">webpage</a>. </p>
<ul>
<li>
<p>Content covered in previous tutorials will be used in later tutorials. </p>
</li>
<li>
<p><strong>New code and or  information <em>should</em> have explanations and or descriptions</strong> attached. </p>
</li>
<li>
<p>Concepts or code covered in previous tutorials will be used without being explaining in entirety.</p>
</li>
<li>
<p>The <a href="https://karpatic.github.io/dataplay/">Dataplay</a> Handbook development techniques covered in the <a href="https://karpatic.github.io/datalabs/">Datalabs</a> Guidebook</p>
</li>
<li>
<p><strong>If content can not be found in the current tutorial and is not covered in previous tutorials, please let me know.</strong></p>
</li>
<li>
<p>This notebook has been optimized for Google Colabs ran on a Chrome Browser. </p>
</li>
<li>
<p>Statements found in the index page on view expressed, responsibility, errors and ommissions, use at risk, and licensing  extend throughout the tutorial.</p>
</li>
</ul>
<p><a href="https://mybinder.org/v2/gh/karpatic/datalab/master?filepath=%2Fnotebooks%2Findex.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a>
<a href="https://colab.research.google.com/github/karpatic/datalab/blob/master/notebooks/index.ipynb"><img src="https://pete88b.github.io/fastpages/assets/badges/colab.svg" alt="Binder" /></a>
<a href="https://github.com/karpatic/datalab/tree/master/notebooks/index.ipynb"><img src="https://pete88b.github.io/fastpages/assets/badges/github.svg" alt="Binder" /></a>
<a href="https://github.com/ellerbrock/open-source-badges/"><img src="https://badges.frapsoft.com/os/v3/open-source.svg?v=103" alt="Open Source Love svg3" /></a></p>
<p><a href="https://github.com/karpatic/dataplay/blob/master/LICENSE"><img src="https://img.shields.io/npm/l/all-contributors.svg?style=flat" alt="NPM License" /></a>
<a href="https://karpatic.github.io"><img src="http://img.shields.io/badge/Status-Active-green.svg" alt="Active" /></a>
<a href="https://pypi.python.org/pypi/dataplay/"><img src="https://img.shields.io/pypi/pyversions/dataplay.svg" alt="Python Versions" /></a>
<a href=""><img src="https://img.shields.io/github/last-commit/karpatic/dataplay.svg?style=flat" alt="GitHub last commit" /></a>
<a href="http://unmaintained.tech/"><img src="http://unmaintained.tech/badge.svg" alt="No Maintenance Intended" /></a> </p>
<p><a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/stars/karpatic/dataplay.svg?style=social&amp;label=Star" alt="GitHub stars" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/watchers/karpatic/dataplay.svg?style=social&amp;label=Watch" alt="GitHub watchers" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/forks/karpatic/dataplay.svg?style=social&amp;label=Fork" alt="GitHub forks" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/followers/karpatic.svg?style=social&amp;label=Follow" alt="GitHub followers" /></a> </p>
<p><a href="https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/karpatic/dataplay%20%F0%9F%A4%97"><img src="https://img.shields.io/twitter/url/https/github.com/karpatic/dataplay.svg?style=social" alt="Tweet" /></a>
<a href="https://twitter.com/bniajfi"><img src="https://img.shields.io/twitter/follow/bniajfi.svg?style=social" alt="Twitter Follow" /></a></p>
<h2>About this Tutorial:</h2>
<h3>Whats Inside?</h3>
<h4><strong>The Tutorial</strong></h4>
<p>In this notebook, the basics of how to perform a merge are introduced.</p>
<ul>
<li>We will merge two datasets</li>
<li>We will merge two datasets using a crosswalk</li>
</ul>
<h4><strong>Objectives</strong></h4>
<p>By the end of this tutorial users should have an understanding of:</p>
<ul>
<li>How dataset merges are performed</li>
<li>The types different union approaches a merge can take</li>
<li>The 'mergeData' function, and how to use it in the future</li>
</ul>
<h1>Guided Walkthrough</h1>
<h2>SETUP</h2>
<p>Install these libraries onto the virtual environment.</p>
!pip install geopandas
!pip install VitalSigns#hide
t = """ 
!pip install nbdev
from google.colab import drive
drive.mount('/content/drive')
%cd /content/drive/My Drive/'Software Development Documents'/dataplay/
"""
# !pip install dataplay#export
from dataplay.intaker import Intake
from VitalSigns.acsDownload import retrieve_acs_data%load_ext autoreload
%autoreload 2The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
ls[0m[01;34mbuild[0m/           [01;34mdataplay[0m/  [01;34mdocs[0m/    Makefile     [01;34mnotebooks[0m/  settings.ini
CONTRIBUTING.md  [01;34mdist[0m/      LICENSE  MANIFEST.in  README.md   setup.py
!nbdev_update_lib -husage: nbdev_update_lib
       [-h]
       [--fname FNAME]
       [--silent SILENT]

Propagates
any change
in the
modules
matching
`fname` to
the
notebooks
that
created
them

optional arguments:
  -h, --help
show this
help
message and
exit
  --fname FNAME
A python
filename or
glob to
convert
  --silent SILENT
Don't print
results
(default:
False)
ls[0m[01;34mbuild[0m/           [01;34mdataplay[0m/  [01;34mdocs[0m/    Makefile     [01;34mnotebooks[0m/  settings.ini
CONTRIBUTING.md  [01;34mdist[0m/      LICENSE  MANIFEST.in  README.md   setup.py
!nbdev_build_libConverted 01_Download_and_Load.ipynb.
Converted 02_Merge_Data.ipynb.
Converted 03_Map_Basics_Intake_and_Operations.ipynb.
Converted 04_nb_2_html.ipynb.
Converted 05_Map_Correlation_Networks.ipynb.
Converted 06_Timelapse_Data_Gifs.ipynb.
Converted index.ipynb.
# individuals not working
!nbdev_update_libConverted intaker.py.
Converted merge.py.
Converted geoms.py.
Converted gifmap.py.
# !nbdev_build_lib --fname './notebooks/01_Download_and_Load.ipynb'
# !nbdev_build_lib --fname './notebooks/02_Merge_Data.ipynb'Converted 01_Download_and_Load.ipynb.
#export
# @title Run: Import Modules

# These imports will handle everything
import numpy as np
import pandas as pd# hide
pd.set_option('display.max_colwidth', -1)
pd.set_option('max_colwidth', 20)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.precision', 2)<h2>Retrieve Datasets</h2>
<p>Our example will merge two simple datasets; pulling CSA names using tract ID's.</p>
<p>The <strong>First</strong> dataset will be obtained from the Census' ACS 5-year serveys. </p>
<p>Functions used to obtain this data were obtained from Tutorial 0) ACS: Explore and Download. </p>
<p>The <strong>Second</strong> dataset is from a publicly accessible link</p>
<h3>Get the Principal dataset.</h3>
<p>We will use the function we created in our last tutorial to download the data!</p>
# Our download function will use Baltimore City's tract, county and state as internal paramters
# Change these values in the cell below using different geographic reference codes will change those parameters
tract = '*'
county = '510'
state = '24'

# Specify the download parameters the function will receieve here
tableId = 'B19001'
year = '17'
saveAcs = Falsedf = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)
df.head()Number of Columns 17
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
    </tr>
    <tr>
      <th>NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Census Tract 2710.02</th>
      <td>1510</td>
      <td>209</td>
      <td>73</td>
      <td>94</td>
      <td>97</td>
      <td>110</td>
      <td>119</td>
      <td>97</td>
      <td>65</td>
      <td>36</td>
      <td>149</td>
      <td>168</td>
      <td>106</td>
      <td>66</td>
      <td>44</td>
      <td>50</td>
      <td>27</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
    </tr>
    <tr>
      <th>Census Tract 2604.02</th>
      <td>1134</td>
      <td>146</td>
      <td>29</td>
      <td>73</td>
      <td>80</td>
      <td>41</td>
      <td>91</td>
      <td>49</td>
      <td>75</td>
      <td>81</td>
      <td>170</td>
      <td>57</td>
      <td>162</td>
      <td>63</td>
      <td>11</td>
      <td>6</td>
      <td>0</td>
      <td>24</td>
      <td>510</td>
      <td>260402</td>
    </tr>
    <tr>
      <th>Census Tract 2712</th>
      <td>2276</td>
      <td>69</td>
      <td>43</td>
      <td>41</td>
      <td>22</td>
      <td>46</td>
      <td>67</td>
      <td>0</td>
      <td>30</td>
      <td>30</td>
      <td>80</td>
      <td>146</td>
      <td>321</td>
      <td>216</td>
      <td>139</td>
      <td>261</td>
      <td>765</td>
      <td>24</td>
      <td>510</td>
      <td>271200</td>
    </tr>
    <tr>
      <th>Census Tract 2804.04</th>
      <td>961</td>
      <td>111</td>
      <td>108</td>
      <td>61</td>
      <td>42</td>
      <td>56</td>
      <td>37</td>
      <td>73</td>
      <td>30</td>
      <td>31</td>
      <td>106</td>
      <td>119</td>
      <td>74</td>
      <td>23</td>
      <td>27</td>
      <td>24</td>
      <td>39</td>
      <td>24</td>
      <td>510</td>
      <td>280404</td>
    </tr>
    <tr>
      <th>Census Tract 901</th>
      <td>1669</td>
      <td>158</td>
      <td>124</td>
      <td>72</td>
      <td>48</td>
      <td>108</td>
      <td>68</td>
      <td>121</td>
      <td>137</td>
      <td>99</td>
      <td>109</td>
      <td>191</td>
      <td>160</td>
      <td>141</td>
      <td>28</td>
      <td>88</td>
      <td>17</td>
      <td>24</td>
      <td>510</td>
      <td>90100</td>
    </tr>
  </tbody>
</table>
</div><h3>Get the Secondary Dataset</h3>
<p>Spatial data can be attained by using the 2010 Census Tract Shapefile Picking <a href="https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&amp;layergroup=Census+Tracts">Tool</a> or search their website for
Tiger/<a href="https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2010.html">Line</a> Shapefiles</p>
<blockquote>
<p>The core TIGER/Line Files and Shapefiles do not include demographic data, but they do contain geographic entity codes (GEOIDs) that can be linked to the Census Bureauâ€™s demographic data, available on data.census.gov.-census.gov</p>
</blockquote>
<p>For this example, we will simply pull a local dataset containing columns labeling tracts within Baltimore City and their corresponding CSA (Community Statistical Area). Typically, we use this dataset internally as a &quot;crosswalk&quot; where-upon a succesfull merge using the tract column, will be merged with a 3rd dataset along it's CSA column.  </p>
# !wget https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv<p>or, Alternately</p>
# !curl https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv	> CSA-to-Tract-2010.csvprint('Boundaries Example:CSA-to-Tract-2010.csv')Boundaries Example:CSA-to-Tract-2010.csv
# Get the Second dataset. 
# Our Example dataset contains Polygon Geometry information. 
# We want to merge this over to our principle dataset. 
# we will grab it by matching on either CSA or Tract

# The url listed below is public.

print('Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv')

from dataplay.intaker import Intake

crosswalk = Intake.getData( 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' ) 
crosswalk.head()Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10100</td>
      <td>24510010100</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10200</td>
      <td>24510010200</td>
      <td>Patterson Park N...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10300</td>
      <td>24510010300</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10400</td>
      <td>24510010400</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10500</td>
      <td>24510010500</td>
      <td>Fells Point</td>
    </tr>
  </tbody>
</table>
</div>crosswalk.columnsIndex(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')<h2>Perform Merge &amp; Save</h2>
<p>The following picture does nothing important but serves as a friendly reminder of the 4 basic join types.</p>
<image src="https://docs.trifacta.com/download/attachments/123830435/JoinVennDiagram.png" height='200px'/>
<ul>
<li>Left - returns all left records, only includes the right record if it has a match</li>
<li>Right - Returns all right records, only includes the left record if it has a match </li>
<li>Full - Returns all records regardless of keys matching</li>
<li>Inner - Returns only records where a key match</li>
</ul>
<p>Get Columns from both datasets to match on</p>
<p>You can get these values from the column values above.</p>
<p>Our Examples will work with the prompted values</p>
print( 'Princpal Columns ' + str(df.columns) + '')
left_on = input("Left on crosswalk column: ('tract') \n" ) or "tract"
print(' \n ');
print( 'Crosswalk Columns ' + str(crosswalk.columns) + '')
right_on = input("Right on crosswalk column: ('TRACTCE10') \n" ) or "TRACTCE10" Princpal Columns Index(['B19001_001E_Total', 'B19001_002E_Total_Less_than_$10,000',
       'B19001_003E_Total_$10,000_to_$14,999',
       'B19001_004E_Total_$15,000_to_$19,999',
       'B19001_005E_Total_$20,000_to_$24,999',
       'B19001_006E_Total_$25,000_to_$29,999',
       'B19001_007E_Total_$30,000_to_$34,999',
       'B19001_008E_Total_$35,000_to_$39,999',
       'B19001_009E_Total_$40,000_to_$44,999',
       'B19001_010E_Total_$45,000_to_$49,999',
       'B19001_011E_Total_$50,000_to_$59,999',
       'B19001_012E_Total_$60,000_to_$74,999',
       'B19001_013E_Total_$75,000_to_$99,999',
       'B19001_014E_Total_$100,000_to_$124,999',
       'B19001_015E_Total_$125,000_to_$149,999',
       'B19001_016E_Total_$150,000_to_$199,999',
       'B19001_017E_Total_$200,000_or_more', 'state', 'county', 'tract'],
      dtype='object')
Left on crosswalk column: ('tract') 

 
 
Crosswalk Columns Index(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')
Right on crosswalk column: ('TRACTCE10') 

<p>Specify how the merge will be performed</p>
<p>We will perform a left merge in this example.</p>
<p>It will return our Principal dataset with columns from the second dataset appended to records where their specified columns match.</p>
how = input("How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) " ) or 'outer'How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) 
<p>Actually perfrom the merge</p>
merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)
merged_df = merged_df.drop(left_on, axis=1)
merged_df.head()<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>568</td>
      <td>128</td>
      <td>24</td>
      <td>44</td>
      <td>41</td>
      <td>4</td>
      <td>25</td>
      <td>20</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
      <td>31</td>
      <td>129</td>
      <td>32</td>
      <td>37</td>
      <td>9</td>
      <td>5</td>
      <td>24</td>
      <td>510</td>
      <td>130805.0</td>
      <td>2.45e+10</td>
      <td>Mount Washington...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>967</td>
      <td>99</td>
      <td>40</td>
      <td>25</td>
      <td>81</td>
      <td>77</td>
      <td>21</td>
      <td>42</td>
      <td>47</td>
      <td>5</td>
      <td>41</td>
      <td>100</td>
      <td>132</td>
      <td>68</td>
      <td>79</td>
      <td>82</td>
      <td>28</td>
      <td>24</td>
      <td>510</td>
      <td>210100.0</td>
      <td>2.45e+10</td>
      <td>Washington Villa...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1139</td>
      <td>191</td>
      <td>93</td>
      <td>81</td>
      <td>67</td>
      <td>63</td>
      <td>41</td>
      <td>51</td>
      <td>76</td>
      <td>68</td>
      <td>50</td>
      <td>120</td>
      <td>114</td>
      <td>22</td>
      <td>0</td>
      <td>33</td>
      <td>69</td>
      <td>24</td>
      <td>510</td>
      <td>270701.0</td>
      <td>2.45e+10</td>
      <td>Harford/Echodale</td>
    </tr>
    <tr>
      <th>3</th>
      <td>808</td>
      <td>195</td>
      <td>114</td>
      <td>80</td>
      <td>49</td>
      <td>76</td>
      <td>81</td>
      <td>26</td>
      <td>70</td>
      <td>0</td>
      <td>33</td>
      <td>19</td>
      <td>31</td>
      <td>13</td>
      <td>0</td>
      <td>15</td>
      <td>6</td>
      <td>24</td>
      <td>510</td>
      <td>190100.0</td>
      <td>2.45e+10</td>
      <td>Southwest Baltimore</td>
    </tr>
    <tr>
      <th>4</th>
      <td>698</td>
      <td>58</td>
      <td>69</td>
      <td>131</td>
      <td>32</td>
      <td>39</td>
      <td>26</td>
      <td>19</td>
      <td>24</td>
      <td>32</td>
      <td>60</td>
      <td>74</td>
      <td>55</td>
      <td>5</td>
      <td>34</td>
      <td>21</td>
      <td>19</td>
      <td>24</td>
      <td>510</td>
      <td>190200.0</td>
      <td>2.45e+10</td>
      <td>Southwest Baltimore</td>
    </tr>
  </tbody>
</table>
</div><p>As you can see, our Census data will now have a CSA appended to it.</p>
# Save Data to User Specified File
# outFile = input("Please enter the new Filename to save the data to ('acs_csa_merge_test': " )
# merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL) <h2>Final Result</h2>
flag = input("Enter a URL? If not ACS data will be used. (Y/N):  " ) or "N"
if (flag == 'y' or flag == 'Y'):
  left_df = Intake.getData( input("Please enter the location of your Left file: " ) )
else:
  tract = input("Please enter tract id (*): " ) or "*"
  county = input("Please enter county id (510): " ) or "510"
  state = input("Please enter state id (24): " ) or "24"
  tableId = input("Please enter acs table id (B19001): " ) or "B19001"
  year = input("Please enter acs year (18): " ) or "18"
  saveAcs = input("Save ACS? (Y/N): " ) or "N"
  left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)

print('right_df Example: CSA-to-Tract-2010.csv')

right_df = Intake.getData( input("Please enter the location of your right_df file: " ) or 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' )
print( 'Left Columns ' + str(left_df.columns))
print( '\n ')
print( 'right_df Columns ' + str(right_df.columns) + '\n')

left_on = input("Left on: " ) or 'tract'
right_on = input("Right on: " ) or 'TRACTCE10'
how = input("How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) " ) or 'outer'

merged_df = pd.merge(left_df, right_df, left_on=left_on, right_on=right_on, how=how)
merged_df = merged_df.drop(left_on, axis=1)

# Save the data
# Save the data
saveFile = input("Save File ('Y' or 'N'): ") or 'N'
if saveFile == 'Y' or saveFile == 'y':
  outFile = input("Saved Filename (Do not include the file extension ): ")
  merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL);Enter a URL? If not ACS data will be used. (Y/N):  
Please enter tract id (*): 
Please enter county id (510): 
Please enter state id (24): 
Please enter acs table id (B19001): 
Please enter acs year (18): 
Save ACS? (Y/N): 
Number of Columns 17
right_df Example: CSA-to-Tract-2010.csv
Please enter the location of your right_df file: 
Left Columns Index(['B19001_001E_Total', 'B19001_002E_Total_Less_than_$10,000',
       'B19001_003E_Total_$10,000_to_$14,999',
       'B19001_004E_Total_$15,000_to_$19,999',
       'B19001_005E_Total_$20,000_to_$24,999',
       'B19001_006E_Total_$25,000_to_$29,999',
       'B19001_007E_Total_$30,000_to_$34,999',
       'B19001_008E_Total_$35,000_to_$39,999',
       'B19001_009E_Total_$40,000_to_$44,999',
       'B19001_010E_Total_$45,000_to_$49,999',
       'B19001_011E_Total_$50,000_to_$59,999',
       'B19001_012E_Total_$60,000_to_$74,999',
       'B19001_013E_Total_$75,000_to_$99,999',
       'B19001_014E_Total_$100,000_to_$124,999',
       'B19001_015E_Total_$125,000_to_$149,999',
       'B19001_016E_Total_$150,000_to_$199,999',
       'B19001_017E_Total_$200,000_or_more', 'state', 'county', 'tract'],
      dtype='object')

 
right_df Columns Index(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')

Left on: 
Right on: 
How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) 
Save File ('Y' or 'N'): 
merged_df.head(1)<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>568</td>
      <td>128</td>
      <td>24</td>
      <td>44</td>
      <td>41</td>
      <td>4</td>
      <td>25</td>
      <td>20</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
      <td>31</td>
      <td>129</td>
      <td>32</td>
      <td>37</td>
      <td>9</td>
      <td>5</td>
      <td>24</td>
      <td>510</td>
      <td>130805.0</td>
      <td>2.45e+10</td>
      <td>Mount Washington...</td>
    </tr>
  </tbody>
</table>
</div><h1>Advanced</h1>
<p>For this next example to work, we will need to import hypothetical csv files</p>
<p><strong>Intro</strong></p>
<p>The following Python function is a bulked out version of the previous notes. </p>
<ul>
<li>It contains everything from the tutorial plus more.</li>
<li>It can be imported and used in future projects or stand alone.</li>
</ul>
<p><strong>Description:</strong> add columns of data from a foreign dataset into a primary dataset along set parameters. </p>
<p><strong>Purpose:</strong> Makes Merging datasets simple</p>
<p><strong>Services</strong></p>
<ul>
<li>Merge two datasets without a crosswalk</li>
<li>Merge two datasets with a crosswalk</li>
</ul>
#export
#@ title Run: Create mergeDatasets()

# Worried about infinit interactive-loops. not an issue atm.
# Crosswalk needs to have exact same column names as left/right datasets
def mergeDatasets(left_ds=False, right_ds=False, crosswalk_ds=False,
                  left_col=False, right_col=False,
                  crosswalk_left_col = False, crosswalk_right_col = False,
                  merge_how=False, # left right or columnname to retrieve
                  interactive=True):
  # Interactive will ask if use_crosswalk unless crosswalk_ds == 'no'

  # 1. Used on Right Dataset in case merge_how is a column to pull. Returns False or Col
  def checkMergeHow(ds, how, interactive):
    inList = how in ['left', 'right', 'outer', 'inner']
    inDf = Intake.checkColumn(ds, how)
    if ( inList or inDf ): return how
    elif ( not interactive ): return False
    else:
      try:
        print('\n Invalid merge column given. \n Please select a value from either list');
        print("\n 1) Pull A single column from the right dataset: ", ds.columns)
        print("OR \n 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) " )
        return checkMergeHow(ds, input("Column Name: " ), interactive);
      except: return False # User probably trying to escape interactivity

  # 2i. Load data via url. Coerce Dtype needed for merge.
  def coerceForMerge( msg, first_ds, second_ds, first_col, second_col, interactive ):
      if (interactive):
        print(f'\n---Casting Datatypes from-to: {msg} Datasets---');
        print('Before Casting: ');
        print('-> Column One: ', first_col, first_ds[first_col].dtype)
        print('-> Column Two: ', second_col, second_ds[second_col].dtype)
      second_ds, second_col = Intake.getAndCheck(second_ds, second_col, interactive)
      first_ds, second_ds, status = Intake.coerce(first_ds, second_ds, first_col, second_col, interactive);
      if (not status and interactive): print('\n There was a problem!');
      if (interactive):
        print('\n After Casting: ');
        print('-> Column One: ', first_col, first_ds[first_col].dtype)
        print('-> Column Two: ', second_col, second_ds[second_col].dtypes)
      return first_ds, second_ds, second_col, status
  # 2ii.
  def mergeAndFilter(msg, first_ds, second_ds, first_col, second_col, how, interactive):
      if interactive:
        print(f'---PERFORMING MERGE : {msg}---');
        print('Column One : ', first_col, first_ds[first_col].dtype)
        print('How: ', how)
        print('Column Two : ', second_col, second_ds[second_col].dtype)
      first_ds = mergeOrPull(first_ds, second_ds, first_col, second_col, how)
      return filterEmpties(first_ds, second_ds, first_col, second_col, how, interactive)

  # Decide to perform a merge or commit a pull
  def mergeOrPull(df, cw, left_on, right_on, how):

    def merge(df, cw, left_on, right_on, how):
      df = pd.merge(df, cw, left_on=left_on, right_on=right_on, how=how)
      # df.drop(left_on, axis=1)
      df[right_on] = df[right_on].fillna(value='empty')
      return df

    def pull(df, cw, left_on, right_on, how):
      crswlk = dict(zip(cw[right_on], cw[how]  ) )
      dtype = df[left_on].dtype
      if dtype =='object':  df[how] = df.apply(lambda row: crswlk.get(str(row[left_on]), "empty"), axis=1)
      elif dtype == 'int64':
        df[how] = df.apply(lambda row: crswlk.get(int(row[left_on]), "empty"), axis=1)
      return df

    mergeType = how in ['left', 'right', 'outer', 'inner']
    if mergeType: return merge(df, cw, left_on, right_on, how)
    else: return pull(df, cw, left_on, right_on, how)

  # 2iiii. Filter between matched records and not.
  def filterEmpties(df, cw, left_on, right_on, how, interactive):
    if how in ['left', 'right', 'outer', 'inner']: how = right_on
    nomatch = df.loc[df[how] == 'empty']
    nomatch = nomatch.sort_values(by=left_on, ascending=True)

    if nomatch.shape[0] > 0:
      # Do the same thing with our foreign tracts
      if(interactive):
        print('\n Local Column Values Not Matched ')
        print(nomatch[left_on].unique() )
        print(len(nomatch[left_on]))
        print('\n Crosswalk Unique Column Values')
        print(cw[right_on].unique() )

    # Create a new column with the tracts value mapped to its corresponding value from the crossswalk
    df[how].replace('empty', np.nan, inplace=True)
    df.dropna(subset=[how], inplace=True)
    # cw = cw.sort_values(by=how, ascending=True)
    return df

  # 0. Retrieve the left and right dataset.
  if (interactive): print('---Handling Left Dataset Options---');
  left_ds, left_col = Intake.getAndCheck(left_ds, left_col, interactive)
  if (interactive): print('Left column:', left_col)

  if (interactive): print('\n---Handling Right Dataset Options---');
  right_ds, right_col  = Intake.getAndCheck(right_ds, right_col, interactive)
  if (interactive): print('Right column:', left_col)

  if (interactive): print(f"\n---Ensuring Compatability Between merge_how (val: '{merge_how}') and the Right Dataset---");
  merge_how = checkMergeHow(right_ds, merge_how, interactive)
  if (interactive): print("Column or ['inner','left','right','outer'] value: ", merge_how)

  # 1. Retrieve the crosswalk dataset: check left-cw, right-cw. try coercing.
  if (interactive): print(f'\n---Checking Crosswalk Dataset Options---')
  # if its a df
  if (not Intake.isPandas(crosswalk_ds)):
    default = str(crosswalk_ds).lower() == 'false'
    # If the user used the the default crosswalk value 'False' as them if they want to use one.
    if (default and interactive ): crosswalk_ds = input("\nProvide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) ") or  False
    # Check if user opted to not use a crosswalk
    use_crosswalk = not ((str(crosswalk_ds).lower() in ["no", '', 'none', 'false']))
    if (use_crosswalk):
      crosswalk_ds, crosswalk_left_col = Intake.getAndCheck(crosswalk_ds, crosswalk_left_col, interactive)
      crosswalk_ds, crosswalk_right_col = Intake.getAndCheck(crosswalk_ds, crosswalk_right_col, interactive)

  # 3. Coerce all datasets for Merge.
  if ( Intake.isPandas(crosswalk_ds) ):
    print('crosswalk_left_col',crosswalk_left_col)
    left_ds, crosswalk_ds, crosswalk_left_col, status = coerceForMerge( 'Left->Crosswalk', left_ds, crosswalk_ds, left_col, crosswalk_left_col, interactive )
    right_ds, crosswalk_ds, crosswalk_right_col, status = coerceForMerge( 'Right->Crosswalk',right_ds, crosswalk_ds, right_col, crosswalk_right_col, interactive )
  else:
    left_ds, right_ds, right_col, status = coerceForMerge('Left->Right', left_ds, right_ds, left_col, right_col, interactive )

  if (interactive): print('\n---All checks complete. Status: ', status, '---\n');
  if ( not status ):
    if (interactive):print('Merge Incomplete. Thank you!');
    return False;
  else:
    if (Intake.isPandas(crosswalk_ds)):
      left_ds = mergeAndFilter('LEFT->CROSSWALK', left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col, interactive)
      left_col = crosswalk_right_col
    left_ds = mergeAndFilter('LEFT->RIGHT', left_ds, right_ds, left_col, right_col, merge_how, interactive)
  return left_ds<h3>Function Explanation</h3>
<p><strong>Input(s):</strong> </p>
<ul>
<li>Dataset url</li>
<li>Crosswalk Url </li>
<li>Right On </li>
<li>Left On </li>
<li>How </li>
<li>New Filename </li>
</ul>
<p><strong>Output:</strong> File</p>
<p><strong>How it works:</strong></p>
<ul>
<li>
<p>Read in datasets</p>
</li>
<li>
<p>Perform Merge</p>
</li>
<li>
<p>If the 'how' parameter is equal to ['left', 'right', 'outer', 'inner']</p>
</li>
<li>
<ul>
<li>then a merge will be performed. </li>
</ul>
</li>
<li>
<p>If a column name is provided in the 'how' parameter</p>
</li>
<li>
<ul>
<li>then that single column will be pulled from the right dataset as a new column in the left_ds.</li>
</ul>
</li>
</ul>
<h2>Function Diagrams</h2>
<p>Diagram the mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/class_diagram_merge_datasets.PNG"><p>mergeDatasets Flow Chart</p>
<img src="https://bniajfi.org/images/mermaid/flow_chart_merge_datasets.PNG"><p>Gannt Chart  mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/gannt_chart_merge_datasets.PNG"><p>Sequence Diagram  mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/sequence_diagram_merge_datasets.PNG"><h2>Function Examples</h2>
# from VitalSigns.acsDownload import retrieve_acs_data
# from dataplay.geoms import readInGeometryData <h4>Interactive Example 1. Merge Esri Data</h4>
# Table: Household Childhood Poverty 
# Hhchpov = Intake.getData("https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson", interactive=True)
# Hhchpov = Hhchpov[['CSA2010', 'hhchpov15',	'hhchpov16',	'hhchpov17',	'hhchpov18']] 
left_ds = "https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson"
left_col = 'CSA2010'

# Table: Household Poverty 
# Hhpov = Intake.getData("https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson", interactive=True)
# Hhpov = Hhpov[['CSA2010', 'hhpov15',	'hhpov16',	'hhpov17',	'hhpov18']] 
right_ds = "https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson"
right_col='CSA2010'

merge_how = 'outer'
interactive = False

merged_df = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds='no',
                  left_col=left_col, right_col=right_col,
                  crosswalk_left_col = False, crosswalk_right_col = False,
                  merge_how=merge_how, # left right or columnname to retrieve
                  interactive=interactive)
merged_df.head()<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15</th>
      <th>hhchpov16</th>
      <th>hhchpov17</th>
      <th>hhchpov18</th>
      <th>hhchpov19</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhpov15</th>
      <th>hhpov16</th>
      <th>hhpov17</th>
      <th>hhpov18</th>
      <th>hhpov19</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.60</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>24.15</td>
      <td>21.28</td>
      <td>20.70</td>
      <td>23.00</td>
      <td>19.18</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Beechfield/Ten H...</td>
      <td>19.42</td>
      <td>21.22</td>
      <td>23.92</td>
      <td>21.90</td>
      <td>15.38</td>
      <td>4.79e+07</td>
      <td>37524.95</td>
      <td>POLYGON ((-76.69...</td>
      <td>2</td>
      <td>11.17</td>
      <td>11.59</td>
      <td>10.47</td>
      <td>10.90</td>
      <td>8.82</td>
      <td>4.79e+07</td>
      <td>37524.95</td>
      <td>POLYGON ((-76.69...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Belair-Edison</td>
      <td>36.88</td>
      <td>36.13</td>
      <td>34.56</td>
      <td>39.74</td>
      <td>41.04</td>
      <td>4.50e+07</td>
      <td>31307.31</td>
      <td>POLYGON ((-76.56...</td>
      <td>3</td>
      <td>18.61</td>
      <td>19.59</td>
      <td>20.27</td>
      <td>22.83</td>
      <td>22.53</td>
      <td>4.50e+07</td>
      <td>31307.31</td>
      <td>POLYGON ((-76.56...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Brooklyn/Curtis ...</td>
      <td>45.01</td>
      <td>46.45</td>
      <td>46.41</td>
      <td>39.89</td>
      <td>41.39</td>
      <td>1.76e+08</td>
      <td>150987.70</td>
      <td>MULTIPOLYGON (((...</td>
      <td>4</td>
      <td>28.36</td>
      <td>26.33</td>
      <td>24.21</td>
      <td>21.54</td>
      <td>24.60</td>
      <td>1.76e+08</td>
      <td>150987.70</td>
      <td>MULTIPOLYGON (((...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Canton</td>
      <td>5.49</td>
      <td>2.99</td>
      <td>4.02</td>
      <td>4.61</td>
      <td>4.83</td>
      <td>1.54e+07</td>
      <td>23338.61</td>
      <td>POLYGON ((-76.57...</td>
      <td>5</td>
      <td>3.00</td>
      <td>2.26</td>
      <td>3.66</td>
      <td>2.05</td>
      <td>2.22</td>
      <td>1.54e+07</td>
      <td>23338.61</td>
      <td>POLYGON ((-76.57...</td>
    </tr>
  </tbody>
</table>
</div><h4>Example 2 ) Get CSA and Geometry with a Crosswalk using 3 links</h4>
# Our download function will use Baltimore City's tract, county and state as internal paramters
# Change these values in the cell below using different geographic reference codes will change those parameters
tract = '*'
county = '510' # '059' # 153 '510'
state = '24' #51
 
# Specify the download parameters the function will receieve here
tableId = 'B19049' # 'B19001'
year = '17'
saveAcs = False import pandas as pd 
import IPython 
# from IPython.core.display import HTML
IPython.core.display.HTML("<style>.rendered_html th {max-width: 200px; overflow:auto;}</style>")
# state, county, tract, tableId, year, saveOriginal, save 
left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)
left_df.head(1) <style>.rendered_html th {max-width: 200px; overflow:auto;}</style>Number of Columns 5
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19049_001E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Total</th>
      <th>B19049_002E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_under_25_years</th>
      <th>B19049_003E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_25_to_44_years</th>
      <th>B19049_004E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_45_to_64_years</th>
      <th>B19049_005E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_65_years_and_over</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
    </tr>
    <tr>
      <th>NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Census Tract 2710.02</th>
      <td>38358</td>
      <td>-666666666</td>
      <td>34219</td>
      <td>40972</td>
      <td>37143</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
    </tr>
  </tbody>
</table>
</div># Table: FDIC Baltimore Banks
# Columns: Bank Name, Address(es), Census Tract
left_ds = left_df
left_col = 'tract'

# Table: Crosswalk Census Communities
# 'TRACT2010', 'GEOID2010', 'CSA2010'
crosswalk_ds = 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv'
crosswalk_left_col = 'TRACTCE10'
crosswalk_right_col = 'CSA2010'

# Table: 
right_ds = 'https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson'
right_col = 'CSA2010'

interactive = False
merge_how = 'outer'

merged_df_geom = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds=crosswalk_ds,
                  left_col=left_col, right_col=right_col,
                  crosswalk_left_col = crosswalk_left_col, crosswalk_right_col = crosswalk_right_col,
                  merge_how=merge_how, # left right or columnname to retrieve
                  interactive=interactive)

merged_df_geom.head()crosswalk_left_col TRACTCE10
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19049_001E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Total</th>
      <th>B19049_002E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_under_25_years</th>
      <th>B19049_003E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_25_to_44_years</th>
      <th>B19049_004E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_45_to_64_years</th>
      <th>B19049_005E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_65_years_and_over</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
      <th>CSA2010</th>
      <th>OBJECTID</th>
      <th>hhpov15</th>
      <th>hhpov16</th>
      <th>hhpov17</th>
      <th>hhpov18</th>
      <th>hhpov19</th>
      <th>Shape__Area</th>
      <th>Shape__Length</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>38358</td>
      <td>-666666666</td>
      <td>34219</td>
      <td>40972</td>
      <td>37143</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44904</td>
      <td>-666666666</td>
      <td>51324</td>
      <td>42083</td>
      <td>37269</td>
      <td>24</td>
      <td>510</td>
      <td>90100</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35707</td>
      <td>2499</td>
      <td>42292</td>
      <td>37361</td>
      <td>29191</td>
      <td>24</td>
      <td>510</td>
      <td>271001</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42231</td>
      <td>-666666666</td>
      <td>46467</td>
      <td>45484</td>
      <td>18750</td>
      <td>24</td>
      <td>510</td>
      <td>260402</td>
      <td>Claremont/Armistead</td>
      <td>9.0</td>
      <td>21.27</td>
      <td>23.59</td>
      <td>24.00</td>
      <td>24.64</td>
      <td>23.88</td>
      <td>6.12e+07</td>
      <td>40104.42</td>
      <td>POLYGON ((-76.52...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>31657</td>
      <td>20800</td>
      <td>26074</td>
      <td>60959</td>
      <td>37396</td>
      <td>24</td>
      <td>510</td>
      <td>260403</td>
      <td>Claremont/Armistead</td>
      <td>9.0</td>
      <td>21.27</td>
      <td>23.59</td>
      <td>24.00</td>
      <td>24.64</td>
      <td>23.88</td>
      <td>6.12e+07</td>
      <td>40104.42</td>
      <td>POLYGON ((-76.52...</td>
    </tr>
  </tbody>
</table>
</div><p>Here we can save the data so that it may be used in later tutorials. </p>
# string = 'test_save_data_with_geom_and_csa'
# merged_df.to_csv(string+'.csv', encoding="utf-8", index=False, quoting=csv.QUOTE_ALL)<h4>Example 3: Ran Alone</h4>
mergeDatasets( ).head(1)---Handling Left Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Left column: CSA2010

---Handling Right Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Right column: CSA2010

---Ensuring Compatability Between merge_how (val: 'False') and the Right Dataset---

 Invalid merge column given. 
 Please select a value from either list

 1) Pull A single column from the right dataset:  Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
OR 
 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) 
Column Name: inner
Column or ['inner','left','right','outer'] value:  inner

---Checking Crosswalk Dataset Options---

Provide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) 

---Casting Datatypes from-to: Left->Right Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---All checks complete. Status:  True ---

---PERFORMING MERGE : LEFT->RIGHT---
Column One :  CSA2010 object
How:  inner
Column Two :  CSA2010 object
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15_x</th>
      <th>hhchpov16_x</th>
      <th>hhchpov17_x</th>
      <th>hhchpov18_x</th>
      <th>hhchpov19_x</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhchpov15_y</th>
      <th>hhchpov16_y</th>
      <th>hhchpov17_y</th>
      <th>hhchpov18_y</th>
      <th>hhchpov19_y</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
  </tbody>
</table>
</div>mergeDatasets().head(1)---Handling Left Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Left column: CSA2010

---Handling Right Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Right column: CSA2010

---Ensuring Compatability Between merge_how (val: 'False') and the Right Dataset---

 Invalid merge column given. 
 Please select a value from either list

 1) Pull A single column from the right dataset:  Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
OR 
 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) 
Column Name: inner
Column or ['inner','left','right','outer'] value:  inner

---Checking Crosswalk Dataset Options---

Provide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
crosswalk_left_col CSA2010

---Casting Datatypes from-to: Left->Crosswalk Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---Casting Datatypes from-to: Right->Crosswalk Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---All checks complete. Status:  True ---

---PERFORMING MERGE : LEFT->CROSSWALK---
Column One :  CSA2010 object
How:  CSA2010
Column Two :  CSA2010 object
---PERFORMING MERGE : LEFT->RIGHT---
Column One :  CSA2010 object
How:  inner
Column Two :  CSA2010 object
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15_x</th>
      <th>hhchpov16_x</th>
      <th>hhchpov17_x</th>
      <th>hhchpov18_x</th>
      <th>hhchpov19_x</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhchpov15_y</th>
      <th>hhchpov16_y</th>
      <th>hhchpov17_y</th>
      <th>hhchpov18_y</th>
      <th>hhchpov19_y</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
  </tbody>
</table>
</div># default_exp merge<p>This Coding Notebook is the <strong>second</strong> in a series.</p>
<p>An Interactive version can be found here <a href="https://colab.research.google.com/github/karpatic/dataplay/blob/master/notebooks/02_Merge_Data.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>.</p>
<p>This colab and more can be found on our <a href="https://karpatic.github.io/dataplay/">webpage</a>. </p>
<ul>
<li>
<p>Content covered in previous tutorials will be used in later tutorials. </p>
</li>
<li>
<p><strong>New code and or  information <em>should</em> have explanations and or descriptions</strong> attached. </p>
</li>
<li>
<p>Concepts or code covered in previous tutorials will be used without being explaining in entirety.</p>
</li>
<li>
<p>The <a href="https://karpatic.github.io/dataplay/">Dataplay</a> Handbook development techniques covered in the <a href="https://karpatic.github.io/datalabs/">Datalabs</a> Guidebook</p>
</li>
<li>
<p><strong>If content can not be found in the current tutorial and is not covered in previous tutorials, please let me know.</strong></p>
</li>
<li>
<p>This notebook has been optimized for Google Colabs ran on a Chrome Browser. </p>
</li>
<li>
<p>Statements found in the index page on view expressed, responsibility, errors and ommissions, use at risk, and licensing  extend throughout the tutorial.</p>
</li>
</ul>
<p><a href="https://mybinder.org/v2/gh/karpatic/datalab/master?filepath=%2Fnotebooks%2Findex.ipynb"><img src="https://mybinder.org/badge_logo.svg" alt="Binder" /></a>
<a href="https://colab.research.google.com/github/karpatic/datalab/blob/master/notebooks/index.ipynb"><img src="https://pete88b.github.io/fastpages/assets/badges/colab.svg" alt="Binder" /></a>
<a href="https://github.com/karpatic/datalab/tree/master/notebooks/index.ipynb"><img src="https://pete88b.github.io/fastpages/assets/badges/github.svg" alt="Binder" /></a>
<a href="https://github.com/ellerbrock/open-source-badges/"><img src="https://badges.frapsoft.com/os/v3/open-source.svg?v=103" alt="Open Source Love svg3" /></a></p>
<p><a href="https://github.com/karpatic/dataplay/blob/master/LICENSE"><img src="https://img.shields.io/npm/l/all-contributors.svg?style=flat" alt="NPM License" /></a>
<a href="https://karpatic.github.io"><img src="http://img.shields.io/badge/Status-Active-green.svg" alt="Active" /></a>
<a href="https://pypi.python.org/pypi/dataplay/"><img src="https://img.shields.io/pypi/pyversions/dataplay.svg" alt="Python Versions" /></a>
<a href=""><img src="https://img.shields.io/github/last-commit/karpatic/dataplay.svg?style=flat" alt="GitHub last commit" /></a>
<a href="http://unmaintained.tech/"><img src="http://unmaintained.tech/badge.svg" alt="No Maintenance Intended" /></a> </p>
<p><a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/stars/karpatic/dataplay.svg?style=social&amp;label=Star" alt="GitHub stars" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/watchers/karpatic/dataplay.svg?style=social&amp;label=Watch" alt="GitHub watchers" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/forks/karpatic/dataplay.svg?style=social&amp;label=Fork" alt="GitHub forks" /></a>
<a href="https://github.com/karpatic/dataplay"><img src="https://img.shields.io/github/followers/karpatic.svg?style=social&amp;label=Follow" alt="GitHub followers" /></a> </p>
<p><a href="https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/karpatic/dataplay%20%F0%9F%A4%97"><img src="https://img.shields.io/twitter/url/https/github.com/karpatic/dataplay.svg?style=social" alt="Tweet" /></a>
<a href="https://twitter.com/bniajfi"><img src="https://img.shields.io/twitter/follow/bniajfi.svg?style=social" alt="Twitter Follow" /></a></p>
<h2>About this Tutorial:</h2>
<h3>Whats Inside?</h3>
<h4><strong>The Tutorial</strong></h4>
<p>In this notebook, the basics of how to perform a merge are introduced.</p>
<ul>
<li>We will merge two datasets</li>
<li>We will merge two datasets using a crosswalk</li>
</ul>
<h4><strong>Objectives</strong></h4>
<p>By the end of this tutorial users should have an understanding of:</p>
<ul>
<li>How dataset merges are performed</li>
<li>The types different union approaches a merge can take</li>
<li>The 'mergeData' function, and how to use it in the future</li>
</ul>
<h1>Guided Walkthrough</h1>
<h2>SETUP</h2>
<p>Install these libraries onto the virtual environment.</p>
!pip install geopandas
!pip install VitalSigns#hide
t = """ 
!pip install nbdev
from google.colab import drive
drive.mount('/content/drive')
%cd /content/drive/My Drive/'Software Development Documents'/dataplay/
"""
# !pip install dataplay#export
from dataplay.intaker import Intake
from VitalSigns.acsDownload import retrieve_acs_data%load_ext autoreload
%autoreload 2The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
ls[0m[01;34mbuild[0m/           [01;34mdataplay[0m/  [01;34mdocs[0m/    Makefile     [01;34mnotebooks[0m/  settings.ini
CONTRIBUTING.md  [01;34mdist[0m/      LICENSE  MANIFEST.in  README.md   setup.py
!nbdev_update_lib -husage: nbdev_update_lib
       [-h]
       [--fname FNAME]
       [--silent SILENT]

Propagates
any change
in the
modules
matching
`fname` to
the
notebooks
that
created
them

optional arguments:
  -h, --help
show this
help
message and
exit
  --fname FNAME
A python
filename or
glob to
convert
  --silent SILENT
Don't print
results
(default:
False)
ls[0m[01;34mbuild[0m/           [01;34mdataplay[0m/  [01;34mdocs[0m/    Makefile     [01;34mnotebooks[0m/  settings.ini
CONTRIBUTING.md  [01;34mdist[0m/      LICENSE  MANIFEST.in  README.md   setup.py
!nbdev_build_libConverted 01_Download_and_Load.ipynb.
Converted 02_Merge_Data.ipynb.
Converted 03_Map_Basics_Intake_and_Operations.ipynb.
Converted 04_nb_2_html.ipynb.
Converted 05_Map_Correlation_Networks.ipynb.
Converted 06_Timelapse_Data_Gifs.ipynb.
Converted index.ipynb.
# individuals not working
!nbdev_update_libConverted intaker.py.
Converted merge.py.
Converted geoms.py.
Converted gifmap.py.
# !nbdev_build_lib --fname './notebooks/01_Download_and_Load.ipynb'
# !nbdev_build_lib --fname './notebooks/02_Merge_Data.ipynb'Converted 01_Download_and_Load.ipynb.
#export
# @title Run: Import Modules

# These imports will handle everything
import numpy as np
import pandas as pd# hide
pd.set_option('display.max_colwidth', -1)
pd.set_option('max_colwidth', 20)
pd.set_option('display.expand_frame_repr', False)
pd.set_option('display.precision', 2)<h2>Retrieve Datasets</h2>
<p>Our example will merge two simple datasets; pulling CSA names using tract ID's.</p>
<p>The <strong>First</strong> dataset will be obtained from the Census' ACS 5-year serveys. </p>
<p>Functions used to obtain this data were obtained from Tutorial 0) ACS: Explore and Download. </p>
<p>The <strong>Second</strong> dataset is from a publicly accessible link</p>
<h3>Get the Principal dataset.</h3>
<p>We will use the function we created in our last tutorial to download the data!</p>
# Our download function will use Baltimore City's tract, county and state as internal paramters
# Change these values in the cell below using different geographic reference codes will change those parameters
tract = '*'
county = '510'
state = '24'

# Specify the download parameters the function will receieve here
tableId = 'B19001'
year = '17'
saveAcs = Falsedf = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)
df.head()Number of Columns 17
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
    </tr>
    <tr>
      <th>NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Census Tract 2710.02</th>
      <td>1510</td>
      <td>209</td>
      <td>73</td>
      <td>94</td>
      <td>97</td>
      <td>110</td>
      <td>119</td>
      <td>97</td>
      <td>65</td>
      <td>36</td>
      <td>149</td>
      <td>168</td>
      <td>106</td>
      <td>66</td>
      <td>44</td>
      <td>50</td>
      <td>27</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
    </tr>
    <tr>
      <th>Census Tract 2604.02</th>
      <td>1134</td>
      <td>146</td>
      <td>29</td>
      <td>73</td>
      <td>80</td>
      <td>41</td>
      <td>91</td>
      <td>49</td>
      <td>75</td>
      <td>81</td>
      <td>170</td>
      <td>57</td>
      <td>162</td>
      <td>63</td>
      <td>11</td>
      <td>6</td>
      <td>0</td>
      <td>24</td>
      <td>510</td>
      <td>260402</td>
    </tr>
    <tr>
      <th>Census Tract 2712</th>
      <td>2276</td>
      <td>69</td>
      <td>43</td>
      <td>41</td>
      <td>22</td>
      <td>46</td>
      <td>67</td>
      <td>0</td>
      <td>30</td>
      <td>30</td>
      <td>80</td>
      <td>146</td>
      <td>321</td>
      <td>216</td>
      <td>139</td>
      <td>261</td>
      <td>765</td>
      <td>24</td>
      <td>510</td>
      <td>271200</td>
    </tr>
    <tr>
      <th>Census Tract 2804.04</th>
      <td>961</td>
      <td>111</td>
      <td>108</td>
      <td>61</td>
      <td>42</td>
      <td>56</td>
      <td>37</td>
      <td>73</td>
      <td>30</td>
      <td>31</td>
      <td>106</td>
      <td>119</td>
      <td>74</td>
      <td>23</td>
      <td>27</td>
      <td>24</td>
      <td>39</td>
      <td>24</td>
      <td>510</td>
      <td>280404</td>
    </tr>
    <tr>
      <th>Census Tract 901</th>
      <td>1669</td>
      <td>158</td>
      <td>124</td>
      <td>72</td>
      <td>48</td>
      <td>108</td>
      <td>68</td>
      <td>121</td>
      <td>137</td>
      <td>99</td>
      <td>109</td>
      <td>191</td>
      <td>160</td>
      <td>141</td>
      <td>28</td>
      <td>88</td>
      <td>17</td>
      <td>24</td>
      <td>510</td>
      <td>90100</td>
    </tr>
  </tbody>
</table>
</div><h3>Get the Secondary Dataset</h3>
<p>Spatial data can be attained by using the 2010 Census Tract Shapefile Picking <a href="https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&amp;layergroup=Census+Tracts">Tool</a> or search their website for
Tiger/<a href="https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2010.html">Line</a> Shapefiles</p>
<blockquote>
<p>The core TIGER/Line Files and Shapefiles do not include demographic data, but they do contain geographic entity codes (GEOIDs) that can be linked to the Census Bureauâ€™s demographic data, available on data.census.gov.-census.gov</p>
</blockquote>
<p>For this example, we will simply pull a local dataset containing columns labeling tracts within Baltimore City and their corresponding CSA (Community Statistical Area). Typically, we use this dataset internally as a &quot;crosswalk&quot; where-upon a succesfull merge using the tract column, will be merged with a 3rd dataset along it's CSA column.  </p>
# !wget https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv<p>or, Alternately</p>
# !curl https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv	> CSA-to-Tract-2010.csvprint('Boundaries Example:CSA-to-Tract-2010.csv')Boundaries Example:CSA-to-Tract-2010.csv
# Get the Second dataset. 
# Our Example dataset contains Polygon Geometry information. 
# We want to merge this over to our principle dataset. 
# we will grab it by matching on either CSA or Tract

# The url listed below is public.

print('Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv')

from dataplay.intaker import Intake

crosswalk = Intake.getData( 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' ) 
crosswalk.head()Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10100</td>
      <td>24510010100</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10200</td>
      <td>24510010200</td>
      <td>Patterson Park N...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10300</td>
      <td>24510010300</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10400</td>
      <td>24510010400</td>
      <td>Canton</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10500</td>
      <td>24510010500</td>
      <td>Fells Point</td>
    </tr>
  </tbody>
</table>
</div>crosswalk.columnsIndex(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')<h2>Perform Merge &amp; Save</h2>
<p>The following picture does nothing important but serves as a friendly reminder of the 4 basic join types.</p>
<image src="https://docs.trifacta.com/download/attachments/123830435/JoinVennDiagram.png" height='200px'/>
<ul>
<li>Left - returns all left records, only includes the right record if it has a match</li>
<li>Right - Returns all right records, only includes the left record if it has a match </li>
<li>Full - Returns all records regardless of keys matching</li>
<li>Inner - Returns only records where a key match</li>
</ul>
<p>Get Columns from both datasets to match on</p>
<p>You can get these values from the column values above.</p>
<p>Our Examples will work with the prompted values</p>
print( 'Princpal Columns ' + str(df.columns) + '')
left_on = input("Left on crosswalk column: ('tract') \n" ) or "tract"
print(' \n ');
print( 'Crosswalk Columns ' + str(crosswalk.columns) + '')
right_on = input("Right on crosswalk column: ('TRACTCE10') \n" ) or "TRACTCE10" Princpal Columns Index(['B19001_001E_Total', 'B19001_002E_Total_Less_than_$10,000',
       'B19001_003E_Total_$10,000_to_$14,999',
       'B19001_004E_Total_$15,000_to_$19,999',
       'B19001_005E_Total_$20,000_to_$24,999',
       'B19001_006E_Total_$25,000_to_$29,999',
       'B19001_007E_Total_$30,000_to_$34,999',
       'B19001_008E_Total_$35,000_to_$39,999',
       'B19001_009E_Total_$40,000_to_$44,999',
       'B19001_010E_Total_$45,000_to_$49,999',
       'B19001_011E_Total_$50,000_to_$59,999',
       'B19001_012E_Total_$60,000_to_$74,999',
       'B19001_013E_Total_$75,000_to_$99,999',
       'B19001_014E_Total_$100,000_to_$124,999',
       'B19001_015E_Total_$125,000_to_$149,999',
       'B19001_016E_Total_$150,000_to_$199,999',
       'B19001_017E_Total_$200,000_or_more', 'state', 'county', 'tract'],
      dtype='object')
Left on crosswalk column: ('tract') 

 
 
Crosswalk Columns Index(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')
Right on crosswalk column: ('TRACTCE10') 

<p>Specify how the merge will be performed</p>
<p>We will perform a left merge in this example.</p>
<p>It will return our Principal dataset with columns from the second dataset appended to records where their specified columns match.</p>
how = input("How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) " ) or 'outer'How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) 
<p>Actually perfrom the merge</p>
merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)
merged_df = merged_df.drop(left_on, axis=1)
merged_df.head()<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>568</td>
      <td>128</td>
      <td>24</td>
      <td>44</td>
      <td>41</td>
      <td>4</td>
      <td>25</td>
      <td>20</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
      <td>31</td>
      <td>129</td>
      <td>32</td>
      <td>37</td>
      <td>9</td>
      <td>5</td>
      <td>24</td>
      <td>510</td>
      <td>130805.0</td>
      <td>2.45e+10</td>
      <td>Mount Washington...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>967</td>
      <td>99</td>
      <td>40</td>
      <td>25</td>
      <td>81</td>
      <td>77</td>
      <td>21</td>
      <td>42</td>
      <td>47</td>
      <td>5</td>
      <td>41</td>
      <td>100</td>
      <td>132</td>
      <td>68</td>
      <td>79</td>
      <td>82</td>
      <td>28</td>
      <td>24</td>
      <td>510</td>
      <td>210100.0</td>
      <td>2.45e+10</td>
      <td>Washington Villa...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1139</td>
      <td>191</td>
      <td>93</td>
      <td>81</td>
      <td>67</td>
      <td>63</td>
      <td>41</td>
      <td>51</td>
      <td>76</td>
      <td>68</td>
      <td>50</td>
      <td>120</td>
      <td>114</td>
      <td>22</td>
      <td>0</td>
      <td>33</td>
      <td>69</td>
      <td>24</td>
      <td>510</td>
      <td>270701.0</td>
      <td>2.45e+10</td>
      <td>Harford/Echodale</td>
    </tr>
    <tr>
      <th>3</th>
      <td>808</td>
      <td>195</td>
      <td>114</td>
      <td>80</td>
      <td>49</td>
      <td>76</td>
      <td>81</td>
      <td>26</td>
      <td>70</td>
      <td>0</td>
      <td>33</td>
      <td>19</td>
      <td>31</td>
      <td>13</td>
      <td>0</td>
      <td>15</td>
      <td>6</td>
      <td>24</td>
      <td>510</td>
      <td>190100.0</td>
      <td>2.45e+10</td>
      <td>Southwest Baltimore</td>
    </tr>
    <tr>
      <th>4</th>
      <td>698</td>
      <td>58</td>
      <td>69</td>
      <td>131</td>
      <td>32</td>
      <td>39</td>
      <td>26</td>
      <td>19</td>
      <td>24</td>
      <td>32</td>
      <td>60</td>
      <td>74</td>
      <td>55</td>
      <td>5</td>
      <td>34</td>
      <td>21</td>
      <td>19</td>
      <td>24</td>
      <td>510</td>
      <td>190200.0</td>
      <td>2.45e+10</td>
      <td>Southwest Baltimore</td>
    </tr>
  </tbody>
</table>
</div><p>As you can see, our Census data will now have a CSA appended to it.</p>
# Save Data to User Specified File
# outFile = input("Please enter the new Filename to save the data to ('acs_csa_merge_test': " )
# merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL) <h2>Final Result</h2>
flag = input("Enter a URL? If not ACS data will be used. (Y/N):  " ) or "N"
if (flag == 'y' or flag == 'Y'):
  left_df = Intake.getData( input("Please enter the location of your Left file: " ) )
else:
  tract = input("Please enter tract id (*): " ) or "*"
  county = input("Please enter county id (510): " ) or "510"
  state = input("Please enter state id (24): " ) or "24"
  tableId = input("Please enter acs table id (B19001): " ) or "B19001"
  year = input("Please enter acs year (18): " ) or "18"
  saveAcs = input("Save ACS? (Y/N): " ) or "N"
  left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)

print('right_df Example: CSA-to-Tract-2010.csv')

right_df = Intake.getData( input("Please enter the location of your right_df file: " ) or 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' )
print( 'Left Columns ' + str(left_df.columns))
print( '\n ')
print( 'right_df Columns ' + str(right_df.columns) + '\n')

left_on = input("Left on: " ) or 'tract'
right_on = input("Right on: " ) or 'TRACTCE10'
how = input("How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) " ) or 'outer'

merged_df = pd.merge(left_df, right_df, left_on=left_on, right_on=right_on, how=how)
merged_df = merged_df.drop(left_on, axis=1)

# Save the data
# Save the data
saveFile = input("Save File ('Y' or 'N'): ") or 'N'
if saveFile == 'Y' or saveFile == 'y':
  outFile = input("Saved Filename (Do not include the file extension ): ")
  merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL);Enter a URL? If not ACS data will be used. (Y/N):  
Please enter tract id (*): 
Please enter county id (510): 
Please enter state id (24): 
Please enter acs table id (B19001): 
Please enter acs year (18): 
Save ACS? (Y/N): 
Number of Columns 17
right_df Example: CSA-to-Tract-2010.csv
Please enter the location of your right_df file: 
Left Columns Index(['B19001_001E_Total', 'B19001_002E_Total_Less_than_$10,000',
       'B19001_003E_Total_$10,000_to_$14,999',
       'B19001_004E_Total_$15,000_to_$19,999',
       'B19001_005E_Total_$20,000_to_$24,999',
       'B19001_006E_Total_$25,000_to_$29,999',
       'B19001_007E_Total_$30,000_to_$34,999',
       'B19001_008E_Total_$35,000_to_$39,999',
       'B19001_009E_Total_$40,000_to_$44,999',
       'B19001_010E_Total_$45,000_to_$49,999',
       'B19001_011E_Total_$50,000_to_$59,999',
       'B19001_012E_Total_$60,000_to_$74,999',
       'B19001_013E_Total_$75,000_to_$99,999',
       'B19001_014E_Total_$100,000_to_$124,999',
       'B19001_015E_Total_$125,000_to_$149,999',
       'B19001_016E_Total_$150,000_to_$199,999',
       'B19001_017E_Total_$200,000_or_more', 'state', 'county', 'tract'],
      dtype='object')

 
right_df Columns Index(['TRACTCE10', 'GEOID10', 'CSA2010'], dtype='object')

Left on: 
Right on: 
How: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™) 
Save File ('Y' or 'N'): 
merged_df.head(1)<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19001_001E_Total</th>
      <th>B19001_002E_Total_Less_than_$10,000</th>
      <th>B19001_003E_Total_$10,000_to_$14,999</th>
      <th>B19001_004E_Total_$15,000_to_$19,999</th>
      <th>B19001_005E_Total_$20,000_to_$24,999</th>
      <th>B19001_006E_Total_$25,000_to_$29,999</th>
      <th>B19001_007E_Total_$30,000_to_$34,999</th>
      <th>B19001_008E_Total_$35,000_to_$39,999</th>
      <th>B19001_009E_Total_$40,000_to_$44,999</th>
      <th>B19001_010E_Total_$45,000_to_$49,999</th>
      <th>B19001_011E_Total_$50,000_to_$59,999</th>
      <th>B19001_012E_Total_$60,000_to_$74,999</th>
      <th>B19001_013E_Total_$75,000_to_$99,999</th>
      <th>B19001_014E_Total_$100,000_to_$124,999</th>
      <th>B19001_015E_Total_$125,000_to_$149,999</th>
      <th>B19001_016E_Total_$150,000_to_$199,999</th>
      <th>B19001_017E_Total_$200,000_or_more</th>
      <th>state</th>
      <th>county</th>
      <th>TRACTCE10</th>
      <th>GEOID10</th>
      <th>CSA2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>568</td>
      <td>128</td>
      <td>24</td>
      <td>44</td>
      <td>41</td>
      <td>4</td>
      <td>25</td>
      <td>20</td>
      <td>0</td>
      <td>21</td>
      <td>18</td>
      <td>31</td>
      <td>129</td>
      <td>32</td>
      <td>37</td>
      <td>9</td>
      <td>5</td>
      <td>24</td>
      <td>510</td>
      <td>130805.0</td>
      <td>2.45e+10</td>
      <td>Mount Washington...</td>
    </tr>
  </tbody>
</table>
</div><h1>Advanced</h1>
<p>For this next example to work, we will need to import hypothetical csv files</p>
<p><strong>Intro</strong></p>
<p>The following Python function is a bulked out version of the previous notes. </p>
<ul>
<li>It contains everything from the tutorial plus more.</li>
<li>It can be imported and used in future projects or stand alone.</li>
</ul>
<p><strong>Description:</strong> add columns of data from a foreign dataset into a primary dataset along set parameters. </p>
<p><strong>Purpose:</strong> Makes Merging datasets simple</p>
<p><strong>Services</strong></p>
<ul>
<li>Merge two datasets without a crosswalk</li>
<li>Merge two datasets with a crosswalk</li>
</ul>
#export
#@ title Run: Create mergeDatasets()

# Worried about infinit interactive-loops. not an issue atm.
# Crosswalk needs to have exact same column names as left/right datasets
def mergeDatasets(left_ds=False, right_ds=False, crosswalk_ds=False,
                  left_col=False, right_col=False,
                  crosswalk_left_col = False, crosswalk_right_col = False,
                  merge_how=False, # left right or columnname to retrieve
                  interactive=True):
  # Interactive will ask if use_crosswalk unless crosswalk_ds == 'no'

  # 1. Used on Right Dataset in case merge_how is a column to pull. Returns False or Col
  def checkMergeHow(ds, how, interactive):
    inList = how in ['left', 'right', 'outer', 'inner']
    inDf = Intake.checkColumn(ds, how)
    if ( inList or inDf ): return how
    elif ( not interactive ): return False
    else:
      try:
        print('\n Invalid merge column given. \n Please select a value from either list');
        print("\n 1) Pull A single column from the right dataset: ", ds.columns)
        print("OR \n 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) " )
        return checkMergeHow(ds, input("Column Name: " ), interactive);
      except: return False # User probably trying to escape interactivity

  # 2i. Load data via url. Coerce Dtype needed for merge.
  def coerceForMerge( msg, first_ds, second_ds, first_col, second_col, interactive ):
      if (interactive):
        print(f'\n---Casting Datatypes from-to: {msg} Datasets---');
        print('Before Casting: ');
        print('-> Column One: ', first_col, first_ds[first_col].dtype)
        print('-> Column Two: ', second_col, second_ds[second_col].dtype)
      second_ds, second_col = Intake.getAndCheck(second_ds, second_col, interactive)
      first_ds, second_ds, status = Intake.coerce(first_ds, second_ds, first_col, second_col, interactive);
      if (not status and interactive): print('\n There was a problem!');
      if (interactive):
        print('\n After Casting: ');
        print('-> Column One: ', first_col, first_ds[first_col].dtype)
        print('-> Column Two: ', second_col, second_ds[second_col].dtypes)
      return first_ds, second_ds, second_col, status
  # 2ii.
  def mergeAndFilter(msg, first_ds, second_ds, first_col, second_col, how, interactive):
      if interactive:
        print(f'---PERFORMING MERGE : {msg}---');
        print('Column One : ', first_col, first_ds[first_col].dtype)
        print('How: ', how)
        print('Column Two : ', second_col, second_ds[second_col].dtype)
      first_ds = mergeOrPull(first_ds, second_ds, first_col, second_col, how)
      return filterEmpties(first_ds, second_ds, first_col, second_col, how, interactive)

  # Decide to perform a merge or commit a pull
  def mergeOrPull(df, cw, left_on, right_on, how):

    def merge(df, cw, left_on, right_on, how):
      df = pd.merge(df, cw, left_on=left_on, right_on=right_on, how=how)
      # df.drop(left_on, axis=1)
      df[right_on] = df[right_on].fillna(value='empty')
      return df

    def pull(df, cw, left_on, right_on, how):
      crswlk = dict(zip(cw[right_on], cw[how]  ) )
      dtype = df[left_on].dtype
      if dtype =='object':  df[how] = df.apply(lambda row: crswlk.get(str(row[left_on]), "empty"), axis=1)
      elif dtype == 'int64':
        df[how] = df.apply(lambda row: crswlk.get(int(row[left_on]), "empty"), axis=1)
      return df

    mergeType = how in ['left', 'right', 'outer', 'inner']
    if mergeType: return merge(df, cw, left_on, right_on, how)
    else: return pull(df, cw, left_on, right_on, how)

  # 2iiii. Filter between matched records and not.
  def filterEmpties(df, cw, left_on, right_on, how, interactive):
    if how in ['left', 'right', 'outer', 'inner']: how = right_on
    nomatch = df.loc[df[how] == 'empty']
    nomatch = nomatch.sort_values(by=left_on, ascending=True)

    if nomatch.shape[0] > 0:
      # Do the same thing with our foreign tracts
      if(interactive):
        print('\n Local Column Values Not Matched ')
        print(nomatch[left_on].unique() )
        print(len(nomatch[left_on]))
        print('\n Crosswalk Unique Column Values')
        print(cw[right_on].unique() )

    # Create a new column with the tracts value mapped to its corresponding value from the crossswalk
    df[how].replace('empty', np.nan, inplace=True)
    df.dropna(subset=[how], inplace=True)
    # cw = cw.sort_values(by=how, ascending=True)
    return df

  # 0. Retrieve the left and right dataset.
  if (interactive): print('---Handling Left Dataset Options---');
  left_ds, left_col = Intake.getAndCheck(left_ds, left_col, interactive)
  if (interactive): print('Left column:', left_col)

  if (interactive): print('\n---Handling Right Dataset Options---');
  right_ds, right_col  = Intake.getAndCheck(right_ds, right_col, interactive)
  if (interactive): print('Right column:', left_col)

  if (interactive): print(f"\n---Ensuring Compatability Between merge_how (val: '{merge_how}') and the Right Dataset---");
  merge_how = checkMergeHow(right_ds, merge_how, interactive)
  if (interactive): print("Column or ['inner','left','right','outer'] value: ", merge_how)

  # 1. Retrieve the crosswalk dataset: check left-cw, right-cw. try coercing.
  if (interactive): print(f'\n---Checking Crosswalk Dataset Options---')
  # if its a df
  if (not Intake.isPandas(crosswalk_ds)):
    default = str(crosswalk_ds).lower() == 'false'
    # If the user used the the default crosswalk value 'False' as them if they want to use one.
    if (default and interactive ): crosswalk_ds = input("\nProvide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) ") or  False
    # Check if user opted to not use a crosswalk
    use_crosswalk = not ((str(crosswalk_ds).lower() in ["no", '', 'none', 'false']))
    if (use_crosswalk):
      crosswalk_ds, crosswalk_left_col = Intake.getAndCheck(crosswalk_ds, crosswalk_left_col, interactive)
      crosswalk_ds, crosswalk_right_col = Intake.getAndCheck(crosswalk_ds, crosswalk_right_col, interactive)

  # 3. Coerce all datasets for Merge.
  if ( Intake.isPandas(crosswalk_ds) ):
    print('crosswalk_left_col',crosswalk_left_col)
    left_ds, crosswalk_ds, crosswalk_left_col, status = coerceForMerge( 'Left->Crosswalk', left_ds, crosswalk_ds, left_col, crosswalk_left_col, interactive )
    right_ds, crosswalk_ds, crosswalk_right_col, status = coerceForMerge( 'Right->Crosswalk',right_ds, crosswalk_ds, right_col, crosswalk_right_col, interactive )
  else:
    left_ds, right_ds, right_col, status = coerceForMerge('Left->Right', left_ds, right_ds, left_col, right_col, interactive )

  if (interactive): print('\n---All checks complete. Status: ', status, '---\n');
  if ( not status ):
    if (interactive):print('Merge Incomplete. Thank you!');
    return False;
  else:
    if (Intake.isPandas(crosswalk_ds)):
      left_ds = mergeAndFilter('LEFT->CROSSWALK', left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col, interactive)
      left_col = crosswalk_right_col
    left_ds = mergeAndFilter('LEFT->RIGHT', left_ds, right_ds, left_col, right_col, merge_how, interactive)
  return left_ds<h3>Function Explanation</h3>
<p><strong>Input(s):</strong> </p>
<ul>
<li>Dataset url</li>
<li>Crosswalk Url </li>
<li>Right On </li>
<li>Left On </li>
<li>How </li>
<li>New Filename </li>
</ul>
<p><strong>Output:</strong> File</p>
<p><strong>How it works:</strong></p>
<ul>
<li>
<p>Read in datasets</p>
</li>
<li>
<p>Perform Merge</p>
</li>
<li>
<p>If the 'how' parameter is equal to ['left', 'right', 'outer', 'inner']</p>
</li>
<li>
<ul>
<li>then a merge will be performed. </li>
</ul>
</li>
<li>
<p>If a column name is provided in the 'how' parameter</p>
</li>
<li>
<ul>
<li>then that single column will be pulled from the right dataset as a new column in the left_ds.</li>
</ul>
</li>
</ul>
<h2>Function Diagrams</h2>
<p>Diagram the mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/class_diagram_merge_datasets.PNG"><p>mergeDatasets Flow Chart</p>
<img src="https://bniajfi.org/images/mermaid/flow_chart_merge_datasets.PNG"><p>Gannt Chart  mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/gannt_chart_merge_datasets.PNG"><p>Sequence Diagram  mergeDatasets()</p>
<img src="https://bniajfi.org/images/mermaid/sequence_diagram_merge_datasets.PNG"><h2>Function Examples</h2>
# from VitalSigns.acsDownload import retrieve_acs_data
# from dataplay.geoms import readInGeometryData <h4>Interactive Example 1. Merge Esri Data</h4>
# Table: Household Childhood Poverty 
# Hhchpov = Intake.getData("https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson", interactive=True)
# Hhchpov = Hhchpov[['CSA2010', 'hhchpov15',	'hhchpov16',	'hhchpov17',	'hhchpov18']] 
left_ds = "https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson"
left_col = 'CSA2010'

# Table: Household Poverty 
# Hhpov = Intake.getData("https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson", interactive=True)
# Hhpov = Hhpov[['CSA2010', 'hhpov15',	'hhpov16',	'hhpov17',	'hhpov18']] 
right_ds = "https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson"
right_col='CSA2010'

merge_how = 'outer'
interactive = False

merged_df = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds='no',
                  left_col=left_col, right_col=right_col,
                  crosswalk_left_col = False, crosswalk_right_col = False,
                  merge_how=merge_how, # left right or columnname to retrieve
                  interactive=interactive)
merged_df.head()<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15</th>
      <th>hhchpov16</th>
      <th>hhchpov17</th>
      <th>hhchpov18</th>
      <th>hhchpov19</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhpov15</th>
      <th>hhpov16</th>
      <th>hhpov17</th>
      <th>hhpov18</th>
      <th>hhpov19</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.60</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>24.15</td>
      <td>21.28</td>
      <td>20.70</td>
      <td>23.00</td>
      <td>19.18</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Beechfield/Ten H...</td>
      <td>19.42</td>
      <td>21.22</td>
      <td>23.92</td>
      <td>21.90</td>
      <td>15.38</td>
      <td>4.79e+07</td>
      <td>37524.95</td>
      <td>POLYGON ((-76.69...</td>
      <td>2</td>
      <td>11.17</td>
      <td>11.59</td>
      <td>10.47</td>
      <td>10.90</td>
      <td>8.82</td>
      <td>4.79e+07</td>
      <td>37524.95</td>
      <td>POLYGON ((-76.69...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Belair-Edison</td>
      <td>36.88</td>
      <td>36.13</td>
      <td>34.56</td>
      <td>39.74</td>
      <td>41.04</td>
      <td>4.50e+07</td>
      <td>31307.31</td>
      <td>POLYGON ((-76.56...</td>
      <td>3</td>
      <td>18.61</td>
      <td>19.59</td>
      <td>20.27</td>
      <td>22.83</td>
      <td>22.53</td>
      <td>4.50e+07</td>
      <td>31307.31</td>
      <td>POLYGON ((-76.56...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Brooklyn/Curtis ...</td>
      <td>45.01</td>
      <td>46.45</td>
      <td>46.41</td>
      <td>39.89</td>
      <td>41.39</td>
      <td>1.76e+08</td>
      <td>150987.70</td>
      <td>MULTIPOLYGON (((...</td>
      <td>4</td>
      <td>28.36</td>
      <td>26.33</td>
      <td>24.21</td>
      <td>21.54</td>
      <td>24.60</td>
      <td>1.76e+08</td>
      <td>150987.70</td>
      <td>MULTIPOLYGON (((...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Canton</td>
      <td>5.49</td>
      <td>2.99</td>
      <td>4.02</td>
      <td>4.61</td>
      <td>4.83</td>
      <td>1.54e+07</td>
      <td>23338.61</td>
      <td>POLYGON ((-76.57...</td>
      <td>5</td>
      <td>3.00</td>
      <td>2.26</td>
      <td>3.66</td>
      <td>2.05</td>
      <td>2.22</td>
      <td>1.54e+07</td>
      <td>23338.61</td>
      <td>POLYGON ((-76.57...</td>
    </tr>
  </tbody>
</table>
</div><h4>Example 2 ) Get CSA and Geometry with a Crosswalk using 3 links</h4>
# Our download function will use Baltimore City's tract, county and state as internal paramters
# Change these values in the cell below using different geographic reference codes will change those parameters
tract = '*'
county = '510' # '059' # 153 '510'
state = '24' #51
 
# Specify the download parameters the function will receieve here
tableId = 'B19049' # 'B19001'
year = '17'
saveAcs = False import pandas as pd 
import IPython 
# from IPython.core.display import HTML
IPython.core.display.HTML("<style>.rendered_html th {max-width: 200px; overflow:auto;}</style>")
# state, county, tract, tableId, year, saveOriginal, save 
left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)
left_df.head(1) <style>.rendered_html th {max-width: 200px; overflow:auto;}</style>Number of Columns 5
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19049_001E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Total</th>
      <th>B19049_002E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_under_25_years</th>
      <th>B19049_003E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_25_to_44_years</th>
      <th>B19049_004E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_45_to_64_years</th>
      <th>B19049_005E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_65_years_and_over</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
    </tr>
    <tr>
      <th>NAME</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Census Tract 2710.02</th>
      <td>38358</td>
      <td>-666666666</td>
      <td>34219</td>
      <td>40972</td>
      <td>37143</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
    </tr>
  </tbody>
</table>
</div># Table: FDIC Baltimore Banks
# Columns: Bank Name, Address(es), Census Tract
left_ds = left_df
left_col = 'tract'

# Table: Crosswalk Census Communities
# 'TRACT2010', 'GEOID2010', 'CSA2010'
crosswalk_ds = 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv'
crosswalk_left_col = 'TRACTCE10'
crosswalk_right_col = 'CSA2010'

# Table: 
right_ds = 'https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson'
right_col = 'CSA2010'

interactive = False
merge_how = 'outer'

merged_df_geom = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds=crosswalk_ds,
                  left_col=left_col, right_col=right_col,
                  crosswalk_left_col = crosswalk_left_col, crosswalk_right_col = crosswalk_right_col,
                  merge_how=merge_how, # left right or columnname to retrieve
                  interactive=interactive)

merged_df_geom.head()crosswalk_left_col TRACTCE10
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B19049_001E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Total</th>
      <th>B19049_002E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_under_25_years</th>
      <th>B19049_003E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_25_to_44_years</th>
      <th>B19049_004E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_45_to_64_years</th>
      <th>B19049_005E_Median_household_income_in_the_past_12_months_(in_2017_inflation-adjusted_dollars)_--_Householder_65_years_and_over</th>
      <th>state</th>
      <th>county</th>
      <th>tract</th>
      <th>CSA2010</th>
      <th>OBJECTID</th>
      <th>hhpov15</th>
      <th>hhpov16</th>
      <th>hhpov17</th>
      <th>hhpov18</th>
      <th>hhpov19</th>
      <th>Shape__Area</th>
      <th>Shape__Length</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>38358</td>
      <td>-666666666</td>
      <td>34219</td>
      <td>40972</td>
      <td>37143</td>
      <td>24</td>
      <td>510</td>
      <td>271002</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44904</td>
      <td>-666666666</td>
      <td>51324</td>
      <td>42083</td>
      <td>37269</td>
      <td>24</td>
      <td>510</td>
      <td>90100</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35707</td>
      <td>2499</td>
      <td>42292</td>
      <td>37361</td>
      <td>29191</td>
      <td>24</td>
      <td>510</td>
      <td>271001</td>
      <td>Greater Govans</td>
      <td>20.0</td>
      <td>21.32</td>
      <td>19.27</td>
      <td>19.53</td>
      <td>17.99</td>
      <td>20.50</td>
      <td>2.27e+07</td>
      <td>22982.13</td>
      <td>POLYGON ((-76.59...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>42231</td>
      <td>-666666666</td>
      <td>46467</td>
      <td>45484</td>
      <td>18750</td>
      <td>24</td>
      <td>510</td>
      <td>260402</td>
      <td>Claremont/Armistead</td>
      <td>9.0</td>
      <td>21.27</td>
      <td>23.59</td>
      <td>24.00</td>
      <td>24.64</td>
      <td>23.88</td>
      <td>6.12e+07</td>
      <td>40104.42</td>
      <td>POLYGON ((-76.52...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>31657</td>
      <td>20800</td>
      <td>26074</td>
      <td>60959</td>
      <td>37396</td>
      <td>24</td>
      <td>510</td>
      <td>260403</td>
      <td>Claremont/Armistead</td>
      <td>9.0</td>
      <td>21.27</td>
      <td>23.59</td>
      <td>24.00</td>
      <td>24.64</td>
      <td>23.88</td>
      <td>6.12e+07</td>
      <td>40104.42</td>
      <td>POLYGON ((-76.52...</td>
    </tr>
  </tbody>
</table>
</div><p>Here we can save the data so that it may be used in later tutorials. </p>
# string = 'test_save_data_with_geom_and_csa'
# merged_df.to_csv(string+'.csv', encoding="utf-8", index=False, quoting=csv.QUOTE_ALL)<h4>Example 3: Ran Alone</h4>
mergeDatasets( ).head(1)---Handling Left Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Left column: CSA2010

---Handling Right Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Right column: CSA2010

---Ensuring Compatability Between merge_how (val: 'False') and the Right Dataset---

 Invalid merge column given. 
 Please select a value from either list

 1) Pull A single column from the right dataset:  Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
OR 
 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) 
Column Name: inner
Column or ['inner','left','right','outer'] value:  inner

---Checking Crosswalk Dataset Options---

Provide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) 

---Casting Datatypes from-to: Left->Right Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---All checks complete. Status:  True ---

---PERFORMING MERGE : LEFT->RIGHT---
Column One :  CSA2010 object
How:  inner
Column Two :  CSA2010 object
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15_x</th>
      <th>hhchpov16_x</th>
      <th>hhchpov17_x</th>
      <th>hhchpov18_x</th>
      <th>hhchpov19_x</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhchpov15_y</th>
      <th>hhchpov16_y</th>
      <th>hhchpov17_y</th>
      <th>hhchpov18_y</th>
      <th>hhchpov19_y</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
  </tbody>
</table>
</div>mergeDatasets().head(1)---Handling Left Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Left column: CSA2010

---Handling Right Dataset Options---
Getting Data From:  False
Error: Try Again?  ( URL/ PATH or  'NO'/ <Empty> ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Right column: CSA2010

---Ensuring Compatability Between merge_how (val: 'False') and the Right Dataset---

 Invalid merge column given. 
 Please select a value from either list

 1) Pull A single column from the right dataset:  Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
OR 
 2) Specify a type of join operation: (â€˜leftâ€™, â€˜rightâ€™, â€˜outerâ€™, â€˜innerâ€™, columnName) 
Column Name: inner
Column or ['inner','left','right','outer'] value:  inner

---Checking Crosswalk Dataset Options---

Provide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Getting Data From:  https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
Invalid column given:  False
Index(['OBJECTID', 'CSA2010', 'hhchpov15', 'hhchpov16', 'hhchpov17',
       'hhchpov18', 'hhchpov19', 'Shape__Area', 'Shape__Length', 'geometry'],
      dtype='object')
Please enter a new column fom the list above.
Column Name: CSA2010
crosswalk_left_col CSA2010

---Casting Datatypes from-to: Left->Crosswalk Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---Casting Datatypes from-to: Right->Crosswalk Datasets---
Before Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

 After Casting: 
-> Column One:  CSA2010 object
-> Column Two:  CSA2010 object

---All checks complete. Status:  True ---

---PERFORMING MERGE : LEFT->CROSSWALK---
Column One :  CSA2010 object
How:  CSA2010
Column Two :  CSA2010 object
---PERFORMING MERGE : LEFT->RIGHT---
Column One :  CSA2010 object
How:  inner
Column Two :  CSA2010 object
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>OBJECTID_x</th>
      <th>CSA2010</th>
      <th>hhchpov15_x</th>
      <th>hhchpov16_x</th>
      <th>hhchpov17_x</th>
      <th>hhchpov18_x</th>
      <th>hhchpov19_x</th>
      <th>Shape__Area_x</th>
      <th>Shape__Length_x</th>
      <th>geometry_x</th>
      <th>OBJECTID_y</th>
      <th>hhchpov15_y</th>
      <th>hhchpov16_y</th>
      <th>hhchpov17_y</th>
      <th>hhchpov18_y</th>
      <th>hhchpov19_y</th>
      <th>Shape__Area_y</th>
      <th>Shape__Length_y</th>
      <th>geometry_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Allendale/Irving...</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
      <td>1</td>
      <td>38.93</td>
      <td>34.73</td>
      <td>32.77</td>
      <td>35.27</td>
      <td>32.6</td>
      <td>6.38e+07</td>
      <td>38770.17</td>
      <td>POLYGON ((-76.65...</td>
    </tr>
  </tbody>
</table>
</div>