# AUTOGENERATED BY NBDEV! DO NOT EDIT!

__all__ = ["index", "modules", "custom_doc_links", "git_url"]

index = {"logger": "13b_transformers.finetuning.ipynb",
         "CACHE_ROOT": "00_file_utils.ipynb",
         "CACHE_DIRECTORY": "00_file_utils.ipynb",
         "url_to_filename": "00_file_utils.ipynb",
         "filename_to_url": "00_file_utils.ipynb",
         "cached_path": "00_file_utils.ipynb",
         "is_url_or_existing_file": "00_file_utils.ipynb",
         "split_s3_path": "00_file_utils.ipynb",
         "s3_request": "00_file_utils.ipynb",
         "get_s3_resource": "00_file_utils.ipynb",
         "s3_etag": "00_file_utils.ipynb",
         "s3_get": "00_file_utils.ipynb",
         "session_with_backoff": "00_file_utils.ipynb",
         "http_get": "00_file_utils.ipynb",
         "get_from_cache": "00_file_utils.ipynb",
         "read_set_from_file": "00_file_utils.ipynb",
         "get_file_extension": "00_file_utils.ipynb",
         "Tqdm": "00_file_utils.ipynb",
         "GatherInputsCallback": "01_callback.ipynb",
         "SetInputsCallback": "01_callback.ipynb",
         "GeneratorCallback": "01_callback.ipynb",
         "HFModelResult": "02_model_hub.ipynb",
         "HFModelHub": "02_model_hub.ipynb",
         "FLAIR_MODELS": "02_model_hub.ipynb",
         "FlairModelResult": "02_model_hub.ipynb",
         "FlairModelHub": "02_model_hub.ipynb",
         "DataLoader.one_batch": "03_model.ipynb",
         "GatherPredsCallback.after_validate": "03_model.ipynb",
         "AdaptiveModel": "03_model.ipynb",
         "EasyWordEmbeddings": "04_embeddings.ipynb",
         "EasyStackedEmbeddings": "04_embeddings.ipynb",
         "EasyDocumentEmbeddings": "04_embeddings.ipynb",
         "TransformersTokenTagger": "05_token_classification.ipynb",
         "FlairTokenTagger": "05_token_classification.ipynb",
         "EasyTokenTagger": "05_token_classification.ipynb",
         "TransformersSequenceClassifier": "06_sequence_classification.ipynb",
         "FlairSequenceClassifier": "06_sequence_classification.ipynb",
         "EasySequenceClassifier": "06_sequence_classification.ipynb",
         "TransformersSummarizer": "07_summarization.ipynb",
         "EasySummarizer": "07_summarization.ipynb",
         "TransformersTranslator": "08_translation.ipynb",
         "EasyTranslator": "08_translation.ipynb",
         "TransformersTextGenerator": "09_text_generation.ipynb",
         "EasyTextGenerator": "09_text_generation.ipynb",
         "QACallback": "10_question_answering.ipynb",
         "TransformersQuestionAnswering": "10_question_answering.ipynb",
         "EasyQuestionAnswering": "10_question_answering.ipynb",
         "LMFineTuner": "11_language_model.ipynb",
         "SequenceClassifierTrainer": "12_training.ipynb",
         "normalize_answer": "13c_transformers.utils_squad_evaluate.ipynb",
         "get_tokens": "13c_transformers.utils_squad_evaluate.ipynb",
         "compute_exact": "13c_transformers.utils_squad_evaluate.ipynb",
         "compute_f1": "13c_transformers.utils_squad_evaluate.ipynb",
         "get_raw_scores": "13c_transformers.utils_squad_evaluate.ipynb",
         "apply_no_ans_threshold": "13c_transformers.utils_squad_evaluate.ipynb",
         "make_eval_dict": "13c_transformers.utils_squad_evaluate.ipynb",
         "merge_eval": "13c_transformers.utils_squad_evaluate.ipynb",
         "find_best_thresh_v2": "13c_transformers.utils_squad_evaluate.ipynb",
         "find_all_best_thresh_v2": "13c_transformers.utils_squad_evaluate.ipynb",
         "find_best_thresh": "13c_transformers.utils_squad_evaluate.ipynb",
         "find_all_best_thresh": "13c_transformers.utils_squad_evaluate.ipynb",
         "squad_evaluate": "13a_transformers.squad_metrics.ipynb",
         "get_final_text": "13a_transformers.squad_metrics.ipynb",
         "compute_predictions_logits": "13a_transformers.squad_metrics.ipynb",
         "compute_predictions_log_probs": "13a_transformers.squad_metrics.ipynb",
         "tqdm": "13b_transformers.finetuning.ipynb",
         "TextDataset": "13b_transformers.finetuning.ipynb",
         "LMFineTunerManual": "13b_transformers.finetuning.ipynb",
         "EVAL_OPTS": "13c_transformers.utils_squad_evaluate.ipynb",
         "OPTS": "13c_transformers.utils_squad_evaluate.ipynb",
         "parse_args": "13c_transformers.utils_squad_evaluate.ipynb",
         "make_qid_to_has_ans": "13c_transformers.utils_squad_evaluate.ipynb",
         "plot_pr_curve": "13c_transformers.utils_squad_evaluate.ipynb",
         "make_precision_recall_eval": "13c_transformers.utils_squad_evaluate.ipynb",
         "run_precision_recall_analysis": "13c_transformers.utils_squad_evaluate.ipynb",
         "histogram_na_prob": "13c_transformers.utils_squad_evaluate.ipynb",
         "main": "13c_transformers.utils_squad_evaluate.ipynb"}

modules = ["file_utils.py",
           "callback.py",
           "model_hub.py",
           "model.py",
           "embeddings.py",
           "token_classification.py",
           "sequence_classification.py",
           "summarization.py",
           "translation.py",
           "text_generation.py",
           "question_answering.py",
           "language_model.py",
           "training.py",
           "transformers/squad_metrics.py",
           "transformers/finetuning.py",
           "transformers/utils_squad_evaluate.py"]

doc_url = "https://novetta.github.io/adaptnlp/"

git_url = "https://github.com/novetta/adaptnlp/tree/master/"

def custom_doc_links(name): return None
